# Hafta 12: GerÃ§ek DÃ¼nya Verisi Toplama ve Ä°ÅŸleme (Data Mining & Preprocessing)

## ğŸ“Œ 1. Ders HakkÄ±nda ve GiriÅŸ
Sosyal AÄŸ Analizi projelerinin %80'i veri toplama, temizleme ve formata sokma (Data Munging / Data Wrangling) ile geÃ§er. Geriye kalan %20 analizdir. GerÃ§ek dÃ¼nya verisi kitaplardaki veya Gephi Ã¶rneklerindeki gibi temiz deÄŸildir; eksiktir, hatalÄ±dÄ±r, gÃ¼rÃ¼ltÃ¼lÃ¼dÃ¼r ve karmaÅŸÄ±ktÄ±r.
*   Ä°simler farklÄ± yazÄ±lÄ±r (Ali Yilmaz vs. Ali YÄ±lmaz, Dr. Ali YÄ±lmaz).
*   MÃ¼kerrer kayÄ±tlar vardÄ±r (Duplicate nodes).
*   Bot hesaplar veri setini kirletir.
*   Veri seti Ã§ok bÃ¼yÃ¼ktÃ¼r, bilgisayarÄ± kilitler.

Bu hafta, bir "Veri Dedektifi" gibi Ã§alÄ±ÅŸacaÄŸÄ±z. Dijital dÃ¼nyadaki izleri (Digital Footprints) nasÄ±l toplayacaÄŸÄ±mÄ±zÄ± Ã¶ÄŸreneceÄŸiz. Twitter (X) gibi platformlarÄ±n API'larÄ±nÄ±, web scraping tekniklerini ve hazÄ±r veri setlerini kullanacaÄŸÄ±z. En Ã¶nemlisi, ham veriden (Ã¶rneÄŸin Tweet metinleri) nasÄ±l anlamlÄ± bir aÄŸ yapÄ±sÄ± (Kim kime mention attÄ±?) kurgulayacaÄŸÄ±mÄ±zÄ±, yani **Veri Modelleme**yi Ã¶ÄŸreneceÄŸiz.

## ğŸ“š 2. Konu BaÅŸlÄ±klarÄ± ve HaftalÄ±k AkÄ±ÅŸ
1.  **Veri KaynaklarÄ±**
    *   **API (Application Programming Interface):** Twitter, YouTube, Reddit, Spotify API'larÄ±.
    *   **Web Scraping:** HTML parselleme (BeautifulSoup, Selenium).
    *   **Anketler:** Geleneksel veri toplama ve matrise dÃ¶kme.
    *   **HazÄ±r ArÅŸivler:** SNAP (Stanford), Kaggle, UCI Repository.
2.  **Veri Modelleri: Ä°liÅŸkiyi TanÄ±mlamak**
    *   **EtkileÅŸim AÄŸlarÄ±:** Mention, Reply, Retweet (YÃ¶nlÃ¼, AÄŸÄ±rlÄ±klÄ±).
    *   **Ä°lgi AÄŸlarÄ± (Bipartite):** KullanÄ±cÄ±-Hashtag, KullanÄ±cÄ±-BeÄŸeni.
    *   **Benzerlik AÄŸlarÄ±:** Metin benzerliÄŸi, Ortak takipÃ§i (Co-follower).
3.  **Veri Temizleme ve Ã–n Ä°ÅŸleme (Preprocessing)**
    *   TekilleÅŸtirme (De-duplication).
    *   VarlÄ±k Ä°smi TanÄ±ma (Named Entity Recognition - NLP).
    *   AnonimleÅŸtirme (Privacy & Ethics - GDPR/KVKK).
4.  **Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼**
    *   JSON'dan Edge List (CSV) oluÅŸturma.
    *   Excel'den matris tÃ¼retme.

## ğŸ“ 3. DetaylÄ± Ä°Ã§erik

### 3.1. API DÃ¼nyasÄ±: Twitter Ã–rneÄŸi
Twitter (X), SAA iÃ§in altÄ±n madenidir. API, yazÄ±lÄ±mlarÄ±n birbiriyle konuÅŸmasÄ±nÄ± saÄŸlar. Python'da `Tweepy` gibi kÃ¼tÃ¼phanelerle veri Ã§ekebiliriz (API eriÅŸimi son yÄ±llarda zorlaÅŸsa da mantÄ±k aynÄ±dÄ±r).
SÃ¼reÃ§ ÅŸÃ¶yledir:
1.  **Developer HesabÄ±:** Platformdan izin alÄ±rsÄ±nÄ±z ve size `API Key` verirler.
2.  **Sorgu (Query):** Bir anahtar kelime (Hashtag) belirlersiniz (#SeÃ§im2024) veya spesifik bir kullanÄ±cÄ±yÄ± seÃ§ersiniz.
3.  **Veri Ã‡ekme:** Son 7 gÃ¼ndeki tweetleri Ã§ekersiniz. Her tweet bir JSON (JavaScript Object Notation) objesidir. Ä°Ã§inde "user" (gÃ¶nderen) ve "entities/user_mentions" (bahsedilenler) alanlarÄ± vardÄ±r.
4.  **Parse Etme:** DÃ¶ngÃ¼ kurarak kimin kime bahsettiÄŸini Ã§Ä±karÄ±rsÄ±nÄ±z: `GÃ¶nderen (Source) -> Bahsedilen (Target)`.

**Rate Limits:** Platformlar veri Ã§ekmeye sÄ±nÄ±r koyar. 15 dakikada en fazla 180 istek gibi. YazÄ±lÄ±mÄ±nÄ±zÄ±n hata verip durmamasÄ± iÃ§in `time.sleep()` komutlarÄ±yla beklemeyi Ã¶ÄŸrenmelisiniz.

### 3.2. Ä°liÅŸkiyi TanÄ±mlamak: "Kenar" Nedir?
Veri aynÄ±dÄ±r ama kuracaÄŸÄ±nÄ±z aÄŸ farklÄ± olabilir. Analiz amacÄ±nÄ±za gÃ¶re kenarÄ± doÄŸru tanÄ±mlamalÄ±sÄ±nÄ±z:
*   **Retweet AÄŸÄ±:** Fikir yayÄ±lÄ±mÄ±nÄ± gÃ¶sterir (Genelde politik analizlerde). YÃ¶nÃ¼ tartÄ±ÅŸmalÄ±dÄ±r: A, B'yi Retweet ederse bilgi B'den A'ya akar (B->A), ama ilgi/saygÄ± A'dan B'ye akar (A->B, Prestige). Genelde A->B olarak modellenir (A, B'yi onaylÄ±yor).
*   **Mention AÄŸÄ±:** Sohbet ve tartÄ±ÅŸmayÄ± gÃ¶sterir. Daha yataydÄ±r. Kavga edenler de birbirini mentionlar. Duygu analizi (Sentiment Analysis) ile birleÅŸtirilmelidir.
*   **Follower AÄŸÄ±:** Statik ve uzun vadelidir. Potansiyel eriÅŸimi gÃ¶sterir. Ã‡ekmesi Ã§ok zordur (Milyonlarca takipÃ§i verisi).

### 3.3. Web Scraping: API Yoksa Ne Var?
EÄŸer bir sitenin API'sÄ± yoksa (Ã¶rneÄŸin bir haber sitesi veya forum), sitenin kodunu (HTML) okuyarak veriyi "kazÄ±rÄ±z".
*   TarayÄ±cÄ±da "Ä°ncele" (Inspect) diyerek sayfa kaynaÄŸÄ±nÄ± gÃ¶rÃ¼ntÃ¼leriz.
*   YazarÄ±n adÄ±nÄ±n hangi etiket (`<span class="author">`) iÃ§inde olduÄŸunu buluruz.
*   Python (BeautifulSoup veya Selenium) ile o etiketi bulup iÃ§indeki metni Ã§ekeriz.
**UyarÄ±:** `robots.txt` dosyasÄ±na ve sitenin kullanÄ±m koÅŸullarÄ±na uymak etik ve yasal bir zorunluluktur. KiÅŸisel verileri izinsiz kazÄ±mak suÃ§ olabilir.

### 3.4. Veri TemizliÄŸi ve NLP
Ä°nsan isimleri baÅŸ belasÄ±dÄ±r. "Ahmet K.", "Ahmet Kaya" ve "ahmet kaya" aynÄ± kiÅŸi mi? Bilgisayar iÃ§in bunlar 3 farklÄ± dÃ¼ÄŸÃ¼mdÃ¼r.
*   **String Matching:** Levenshtein mesafesi gibi algoritmalarla birbirine Ã§ok benzeyen (karakter hatasÄ± olan) isimleri tespit edip birleÅŸtiririz.
*   **Normalizasyon:** Her ÅŸeyi kÃ¼Ã§Ã¼k harfe Ã§evirme, TÃ¼rkÃ§e karakterleri dÃ¼zeltme.
*   **DoÄŸal Dil Ä°ÅŸleme (NLP):** Bir gazete haberinden aÄŸ Ã§Ä±karacaksanÄ±z, metnin iÃ§indeki "KiÅŸi" ve "Kurum" isimlerini otomatik tanÄ±yan yapay zeka modelleri (Spacy, NLTK - Named Entity Recognition) kullanÄ±rsÄ±nÄ±z. Metinden: "ErdoÄŸan, Putin ile gÃ¶rÃ¼ÅŸtÃ¼." cÃ¼mlesini alÄ±p `ErdoÄŸan --(gÃ¶rÃ¼ÅŸtÃ¼)--> Putin` aÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼rsÃ¼nÃ¼z.

### 3.5. Etik Sorumluluk
SÄ±rf veri "aÃ§Ä±k" diye her ÅŸeyi yayÄ±nlayamazsÄ±nÄ±z. "Do no harm" (Zarar verme) ilkesi esastÄ±r.
*   KiÅŸisel verilerin (telefon, adres) ifÅŸasÄ± (Doxing).
*   Hassas konularda (saÄŸlÄ±k, politika, cinsel yÃ¶nelim) kullanÄ±cÄ±larÄ±n fiÅŸlenmesi riski.
*   BaÄŸlamdan koparma.
AraÅŸtÄ±rmacÄ±lar genellikle kullanÄ±cÄ± ID'lerini ÅŸifreleyerek (Hashing) veya isimleri gizleyerek (Node 1, Node 2...) Ã§alÄ±ÅŸÄ±r ve sadece makro istatistikleri paylaÅŸÄ±r.

## ğŸ”‘ 4. Anahtar Kavramlar SÃ¶zlÃ¼ÄŸÃ¼
*   **API (Uygulama Programlama ArayÃ¼zÃ¼):** Veriye eriÅŸim kapÄ±sÄ±.
*   **JSON (JavaScript Object Notation):** Modern verinin taÅŸÄ±nma formatÄ± (Ä°Ã§ iÃ§e geÃ§miÅŸ sÃ¶zlÃ¼kler gibi). OkumasÄ± kolaydÄ±r.
*   **Rate Limiting:** API'Ä±n aÅŸÄ±rÄ± kullanÄ±mÄ±nÄ± engellemek iÃ§in koyduÄŸu hÄ±z sÄ±nÄ±rÄ±.
*   **Web Scraping:** Web sayfalarÄ±ndan otomatik veri Ã§ekme.
*   **Bipartite Projection:** Ä°ki modlu (KullanÄ±cÄ±-Hashtag) aÄŸÄ± tek modlu (Hashtag-Hashtag veya KullanÄ±cÄ±-KullanÄ±cÄ±) aÄŸa indirgeme iÅŸlemi. (AynÄ± hashtag'i kullanan kullanÄ±cÄ±lar birbirine baÄŸlanÄ±r).

## ğŸ›  5. Kaynaklar ve Ä°leri Okuma Ã–nerileri
### Veri KaynaklarÄ±
*   **SNAP (Stanford Network Analysis Platform):** Jure Leskovec tarafÄ±ndan yÃ¶netilen, devasa hazÄ±r aÄŸ veri setleri (Facebook, Enron E-mail, Amazon co-purchase). Ä°lk denemeler iÃ§in mÃ¼kemmeldir. (http://snap.stanford.edu)
*   **Kaggle:** Veri bilimi yarÄ±ÅŸma platformu. "Social Network" diye aratÄ±rsanÄ±z yÃ¼zlerce temiz veri seti bulursunuz.

### AraÃ§lar (Python)
*   **Tweepy:** Twitter API iÃ§in kÃ¼tÃ¼phane.
*   **BeautifulSoup:** HTML parsing iÃ§in.
*   **Pandas:** Veri Ã§erÃ§evesi (Dataframe) yÃ¶netimi iÃ§in (Excel'in Python hali). Veriyi temizlemek iÃ§in en iyi araÃ§tÄ±r.

## ğŸ¯ 6. HaftanÄ±n Ã–zeti ve Gelecek Haftaya BakÄ±ÅŸ
Bu hafta ellerimizi kirlettik. Veriyi kaynaÄŸÄ±ndan (madenden) Ã§Ä±kardÄ±k, iÅŸledik ve saf bir "Edge List" haline getirdik. ArtÄ±k elimizde analiz edilmeye hazÄ±r, gerÃ§ek bir aÄŸ var. Ama bu rakamlar ne anlatÄ±yor?
Gelecek hafta, dÃ¶nem boyunca Ã¶ÄŸrendiÄŸimiz **tÃ¼m** teknikleri (Merkezilik, Topluluklar, GÃ¶rselleÅŸtirme) bu veri Ã¼zerinde uÃ§tan uca uygulayacaÄŸÄ±mÄ±z kapsamlÄ± bir **Vaka Analizi (Case Study)** yapacaÄŸÄ±z. SayÄ±larÄ±n iÃ§inden "hikayeyi" Ã§Ä±karacaÄŸÄ±z. DedektifliÄŸin son aÅŸamasÄ±: Ã‡Ã¶zÃ¼m.
