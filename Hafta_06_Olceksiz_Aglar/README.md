# Hafta 6: 칐l칞eksiz A륿ar ve Barab치si-Albert Modeli (Scale-Free Networks)

## 游늷 1. Ders Hakk캼nda ve Giri
룟 ana kadar inceledi를miz Erd콈s-R칠nyi (Rastsal) ve Watts-Strogatz (K칲칞칲k D칲nya) modellerinin ortak, fakat hatal캼 bir varsay캼m캼 vard캼: "A륷aki herkes a르캼 yukar캼 e를ttir." Bu modellerde, bir ki를nin arkada say캼s캼 veya bir web sayfas캼n캼n link say캼s캼 ortalama etraf캼nda (칂an erisi/Poisson) da캼l캼r. Yani ortalamadan 칞ok sapan, "a캼r캼" dereceli d칲칲mler yoktur.

Ancak 1999 y캼l캼nda Albert-L치szl칩 Barab치si ve 칬rencisi R칠ka Albert, World Wide Web (WWW) haritas캼n캼 칞캼kard캼klar캼nda 릂ke edici bir ger칞ekle kar캼la릆캼lar: Web, rastgele de를ldi. Milyonlarca sayfa sadece 1-2 link al캼rken, Google, Yahoo veya Amazon gibi baz캼 sayfalar *milyonlarca* link al캼yordu. Bu da캼l캼m bir 칞an erisi de를ldi, uzun kuyruklu bir **Kuvvet Yasas캼 (Power Law)** idi.

Bu hafta, modern a biliminin belki de en 칬nemli ke륹i olan **칐l칞eksiz A륿ar (Scale-Free Networks)** teorisini ve bu a륿ar캼n nas캼l olu릆u릇nu a칞캼klayan **Barab치si-Albert (BA) Modeli**ni inceleyece를z. Hub'lar캼n (Merkezcillerin) nas캼l do륷u릇nu, "Zengin daha da zenginle를r" mekanizmas캼n캼 ve bu yap캼n캼n internetin g칲venli를, vir칲slerin yay캼l캼m캼 ve kanser ara릆캼rmalar캼 i칞in ne anlama geldi를ni g칬rece를z.

## 游닄 2. Konu Ba륿캼klar캼 ve Haftal캼k Ak캼
1.  **Kuvvet Yasas캼 (Power Law) ve 칐l칞ek**
    *   Normal Da캼l캼m (Boy uzunlu릇) vs. Kuvvet Yasas캼 (Servet da캼l캼m캼).
    *   "칐l칞ek" kavram캼 nedir ve neden "칐l칞eksiz" denir?
    *   Matematiksel tan캼m: $P(k) \sim k^{-\gamma}$.
    *   80/20 Kural캼 (Pareto 캻lkesi) ile ili륾isi.
2.  **Barab치si-Albert (BA) Modeli**
    *   Mevcut modellerin (ER ve WS) eksikli를: Statik yap캼.
    *   캻ki temel mekanizma:
        1.  **B칲y칲me (Growth):** A르 s칲rekli yeni d칲칲mler eklenir.
        2.  **Tercihli Ba륿anma (Preferential Attachment):** Yeni gelenler, pop칲ler olana ba륿an캼r.
3.  **칐l칞eksiz A륿ar캼n 칐zellikleri**
    *   Hub'lar캼n varl캼캼.
    *   Ultra-K칲칞칲k D칲nya (Ultra-Small World) 칬zelli를.
4.  **A Dayan캼kl캼l캼캼: G칲rb칲zl칲k ve K캼r캼lganl캼k**
    *   Rastgele hatalara kar캼 G칲rb칲zl칲k (Robustness).
    *   Bilin칞li sald캼r캼lara kar캼 K캼r캼lganl캼k (Vulnerability).
    *   A를l Topu릇 problemi.

## 游닇 3. Detayl캼 캻칞erik

### 3.1. Normal Da캼l캼m vs. Kuvvet Yasas캼
Do르daki bir칞ok olay (insan boyu, IQ seviyesi) **Normal Da캼l캼m** g칬sterir. Ortalama bir de른r vard캼r ve herkes bu ortalamaya yak캼nd캼r. Boyu 3 metre olan bir insan bulamazs캼n캼z. Boyunuz ortalamadan ne kadar saparsa, bulunma ihtimaliniz o kadar h캼zla (칲stel olarak) d칲른r.
Ancak karma캼k sistemlerde (deprem b칲y칲kl칲kleri, ay kraterlerinin 칞ap캼, kelime kullan캼m s캼kl캼klar캼, 른hir n칲fuslar캼, ki를sel servet) **Kuvvet Yasas캼 (Power Law)** ge칞erlidir.
*   **Normal Da캼l캼m:** Tepesi vard캼r, simetriktir.
*   **Kuvvet Yasas캼:** $P(k) = C \cdot k^{-\gamma}$. Kuyru릇 칞ok uzundur ("Fat Tail").
*   **Anlam캼:** Kuvvet yasas캼nda, 칞ok nadir g칬r칲len ama etkisi devasa olan "Siyah Ku릇" olaylar캼 m칲mk칲nd칲r. 3 metre boyunda insan yoktur ama ortalamadan milyonlarca kat zengin (Bill Gates) insanlar vard캼r. Veya ortalamadan milyonlarca kat fazla takip칞isi olan Twitter hesaplar캼 vard캼r. Pareto'nun me륻ur 80/20 kural캼 (캻talyan topraklar캼n캼n %80'ine n칲fusun %20'si sahiptir) bunun bir yans캼mas캼d캼r.

**Neden "칐l칞eksiz" (Scale-Free)?**
Normal da캼l캼m캼n bir "칬l칞e를" (karakteristik boyutu, yani ortalamas캼) vard캼r. "캻nsanlar ortalama 170cm'dir" diyebilirsiniz. Ancak kuvvet yasas캼nda tipik bir d칲칲m yoktur. Herhangi bir 칬l칞ekte bakt캼캼n캼zda yap캼 ayn캼 g칬r칲n칲r (Fraktal 칬zellik). K칲칞칲k bir mahalleye de baksan캼z, t칲m d칲nyaya da baksan캼z, yap캼 ayn캼d캼r: 칂ok say캼da k칲칞칲kler, az say캼da devler. Bu y칲zden "칬l칞eksiz" denir.

### 3.2. Barab치si-Albert (BA) Modeli: "Zengin Daha da Zenginle를r"
Barab치si ve Albert, Erd콈s-R칠nyi ve Watts-Strogatz modellerinin neden ger칞ek a륿ar캼 (WWW) a칞캼klayamad캼캼n캼 d칲칲nd칲ler. Bu modeller iki 른yi ihmal ediyordu:
1.  **A륿ar b칲y칲kt칲r ama statik de를ldir:** ER modelinde $N$ ba릆an sabittir. Oysa ger칞ek a륿ar (Web, At캼f a륿ar캼) s칲rekli b칲y칲r; yeni sayfalar, yeni makaleler eklenir. Zaman boyutu vard캼r.
2.  **Ba륿ant캼lar rastgele de를ldir:** Yeni bir web sayfas캼 a칞t캼캼n캼zda rastgele bir sayfaya link vermezsiniz. Bildi를niz, pop칲ler, referans de른ri olan (derecesi y칲ksek) sayfalara (Google, CNN) link verirsiniz.

BA Modeli bu iki kural캼 uygular:
*   **Ad캼m 0:** $m_0$ adet d칲칲mle ba륿a.
*   **Ad캼m 1 (B칲y칲me):** Her zaman ad캼m캼nda a르 yeni bir d칲칲m ekle. Bu d칲칲m, mevcut d칲칲mlerden $m$ tanesine ba륿ans캼n ($m \leq m_0$).
*   **Ad캼m 2 (Tercihli Ba륿anma):** Yeni d칲칲m칲n, mevcut bir $i$ d칲칲m칲ne ba륿anma olas캼l캼캼 ($\Pi_i$), o d칲칲m칲n derecesi ($k_i$) ile orant캼l캼d캼r.
    $$ \Pi_i = \frac{k_i}{\sum_j k_j} $$
    Yani, derecesi y칲ksek olan캼n se칞ilme 르ns캼 daha y칲ksektir.

Bu basit algoritma 칞al캼릆캼r캼ld캼캼nda, ortaya 칞캼kan a캼n derece da캼l캼m캼 kendili를nden bir Kuvvet Yasas캼na d칬n칲칲r ($P(k) \sim k^{-3}$). Bu, bir mucizedir; karma캼k bir yap캼y캼 a칞캼klamak i칞in karma캼k kurallara gerek yoktur, sadece b칲y칲me ve tercihli ba륿anma yeterlidir. Buna sosyal bilimlerde "Matthaeus Etkisi" (Matthew Effect) denir.

### 3.3. Hub'lar (Merkezciller)
Tercihli ba륿anma mekanizmas캼 do르l olarak **Hub**'lar캼 olu릆urur. A르 erken kat캼lan d칲칲mler (First mover advantage), zamanla daha fazla ba륿ant캼 toplar, daha fazla ba륿ant캼 toplad캼k칞a daha 칞ekici hale gelir ve daha h캼zl캼 b칲y칲rler.
Hub'lar, a캼n yap캼s캼n캼 bir arada tutan tutkald캼r ve a캼n 칞ap캼n캼 inan캼lmaz derecede k칲칞칲lt칲r (**Ultra-Small World**). Rastsal a륿arda 칞ap $\ln N$ ile b칲y칲rken, 칬l칞eksiz a륿arda $\ln \ln N$ ile b칲y칲r. Yani 칬l칞eksiz a륿ar 칞ok daha "k칲칞칲kt칲r". Milyonlarca d칲칲m olsa bile, Hub'lar sayesinde herkes birbirine 2-3 ad캼m uzaktad캼r.

### 3.4. A를l Topu릇: G칲rb칲zl칲k ve K캼r캼lganl캼k
칐l칞eksiz a륿ar캼n mimarisi, onlara hem b칲y칲k bir g칲칞 hem de 칬l칲mc칲l bir zay캼fl캼k verir.

#### G칲칞l칲 Y칬n: Hata Tolerans캼
캻nternet gibi 칬l칞eksiz bir a륷an rastgele routerlar bozulsa ne olur? Hi칞bir 른y olmaz. 칂칲nk칲 d칲칲mlerin %80'i d칲칲k derecelidir. Rastgele bir ar캼zan캼n kritik bir Hub'캼 vurma ihtimali 칞ok d칲칲kt칲r. D칲칲mlerin %90'캼n캼 rastgele silseniz bile a hala ba륿ant캼l캼 kal캼r. Bu, do르n캼n bir savunma mekanizmas캼d캼r (Protein a륿ar캼 da b칬yledir, mutasyonlara dayan캼kl캼d캼r).

#### Zay캼f Y칬n: Sald캼r캼ya A칞캼kl캼k
E른r zeki bir d칲릀an a캼 biliyorsa ve rastgele sald캼rmak yerine, derecesine g칬re s캼ralay캼p en b칲y칲k Hub'lar캼 (ilk %1'i) hedef al캼rsa ne olur? A an캼nda 칞칬ker, par칞alan캼r ve i륿evsiz hale gelir.
*   Havaliman캼 a륿ar캼nda birka칞 ana hub'캼n (Londra, New York, Frankfurt) kapat캼lmas캼 t칲m d칲nya trafi를ni kilitler.
*   Salg캼n hastal캼klarla m칲cadelede rastgele a캼 yapmak yerine, "s칲per yay캼c캼lar캼" (Hub'lar캼) bulup a캼lamak 칞ok daha etkilidir (Ba캼캼klama stratejisi).

### 3.5. Sonu칞
Barab치si-Albert modeli, a biliminde bir paradigma de를를mi yaratm캼릆캼r. Art캼k biliyoruz ki sosyal ve teknolojik sistemler rastgele de를ldir; hiyerar를ktir, rekabet칞idir ve kazanan캼n her 른yi ald캼캼 (winner-take-all) dinamiklere sahiptir.

## 游댐 4. Anahtar Kavramlar S칬zl칲칲
*   **Scale-Free Network (칐l칞eksiz A):** Derece da캼l캼m캼 kuvvet yasas캼na uyan, karakteristik bir 칬l칞e를 olmayan a.
*   **Power Law (Kuvvet Yasas캼):** $P(k) \sim k^{-\gamma}$. "Uzun kuyruk" da캼l캼m캼.
*   **Preferential Attachment (Tercihli Ba륿anma):** Ba륿ant캼 kurarken pop칲ler olan캼 tercih etme e를limi. Zengin daha da zenginle를r.
*   **Hub:** A캼r캼 derecede y칲ksek ba륿ant캼ya sahip, a캼n 칞imentosu olan d칲칲m.
*   **Robustness (G칲rb칲zl칲k):** Sistemin i칞sel veya d캼릅al hatalara kar캼 i륿evini s칲rd칲rebilme yetene를.

## 游 5. Kaynaklar ve 캻leri Okuma 칐nerileri
### Makale
*   **Barab치si, A. L., & Albert, R. (1999).** "Emergence of scaling in random networks". *Science*, 286(5439), 509-512. (칐l칞eksiz a륿ar캼n do릇릇nu m칲jdeleyen seminal makale).

### Kitaplar
*   **"Linked"** - Albert-L치szl칩 Barab치si: Yazar캼n bu ke륹i nas캼l yapt캼캼n캼 anlatt캼캼 pop칲ler bilim kitab캼.
*   **"The Long Tail"** - Chris Anderson: Kuvvet yasas캼n캼n (uzun kuyruk) internet ekonomisini (Amazon, Netflix) nas캼l de를릆irdi를ni anlatan i륿etme kitab캼.

### Video / Belgesel
*   **"Connected: The Power of Six Degrees"** (Discovery Channel belgeseli, Barab치si ile r칬portajlar i칞erir).

## 游꿢 6. Haftan캼n 칐zeti ve Gelecek Haftaya Bak캼
Bu hafta a modelleri 칲칞lemesini (Rastsal, K칲칞칲k D칲nya, 칐l칞eksiz) tamamlad캼k. Art캼k a륿ar캼n nas캼l olu릆u릇na dair g칲칞l칲 teorilerimiz var. Ger칞ek hayat캼n karma르s캼nda "Hub"lar캼n neden vazge칞ilmez ama tehlikeli oldu릇nu anlad캼k.
칐n칲m칲zdeki hafta, a륿ar캼 "modellemekten" tekrar "칬l칞meye" d칬nece를z. Ancak bu sefer sadece merkezilik (d칲칲m puan캼) de를l, a캼n genel yap캼s캼n캼 (topolojisini) 칬l칞en geli릀i metriklere bakaca캼z. A륿ar ne kadar yo릇n? Kutupla릀a (Assortativity) var m캼? Neden pop칲ler insanlar캼n arkada륿ar캼 da pop칲ler oluyor? **A De른rlendirme Metrikleri** dersinde g칬r칲릀ek 칲zere.
